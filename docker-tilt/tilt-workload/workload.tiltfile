load('ext://helm_resource', 'helm_resource', 'helm_repo')
load('ext://restart_process', 'docker_build_with_restart')
load("../consts.tiltfile", "consts")

# Set autoreload only manual
#trigger_mode(TRIGGER_MODE_MANUAL)

# Return a list containing the result of local(command) split by newlines.
def local_as_list(command):
   return str(local(command)).rstrip("\n").split("\n")

allow_k8s_contexts("{0}-admin@{0}".format(consts.get("wkld_cluster_name")))

if not os.path.exists("target-exporter"):
  fail('Please "git clone" the target-exporter repo in folder "tilt-workload".')

if not os.path.exists("job-submission-platform"):
  fail('Please "git clone" the job-submission-platform repo in folder "tilt-workload".')

if not os.path.exists("pyzhm"):
  fail('Please "git clone" the pyZHM repo in folder "tilt-workload/pyzhm.')

# Deploy target-exporter
# Inject node names
nodes_name_prefix = "{}-{}".format(consts.get("wkld_cluster_name"), consts.get("machinedeploy_name"))
node_names = local_as_list("kubectl get nodes -o custom-columns=NAME:.metadata.name | grep {}".format(nodes_name_prefix))
#random_targets = local_as_list("shuf -i 1-100 -n {}".format(len(node_names)))

kubeconfig = "{}.kubeconfig".format(consts.get("wkld_cluster_name"))
if not os.path.exists("target-exporter/charts/target-exporter/ecoqube-dev.kubeconfig") or str(read_file("../{}".format(kubeconfig))) != str(read_file("target-exporter/charts/target-exporter/ecoqube-dev.kubeconfig")):
  print("kubeconfig has changed")
  local("cp ../{} target-exporter/charts/target-exporter/ecoqube-dev.kubeconfig".format(kubeconfig))

# Target exporter local compiling
local_resource(
  "target-exporter-compile",
  'cd target-exporter/ && CGO_ENABLED=0 GOOS=linux GOARCH=amd64 go build -gcflags="all=-N -l" -o ./build/target-exporter ',
  deps=['./target-exporter/main.go', './target-exporter/pkg'])

# Create yaml from node names and inject them in target-exporter config
targets = dict()
targetsList = dict()
for i in range(0, len(node_names)):
#  targetsList.update({node_names[i]: random_targets[i]})
   targetsList.update({node_names[i]: 50})

targets = {"targets": targetsList}
print(str(encode_yaml(targets)))

pyzhmNodeLabels = [
    "L1",
    "L3",
    "L5",
    "L7",
    "L9",
    "L11",
    "L13",
    "L15",
    "L17",
    "L19",
    "L21",
    "L23",
    "R1",
    "R3",
    "R5",
    "R7",
    "R9",
    "R11",
    "R13",
    "R15",
    "R17",
    "R19",
    "R21",
    "R23",
]

# Very hardcoded!!
# IPs are BMC IP in EMPA DC, must be connected to VPN to test. IPs are taken at random from real cluster to simulate a real server for IPMI stuff.

pyzhmMappings = dict()

for i in range(0, len(pyzhmNodeLabels)):
  pyzhmMappings[pyzhmNodeLabels[i]] = node_names[i % len(node_names)]

print(pyzhmMappings)

pyzhmNodeMappings = { "pyzhmNodeMappings": pyzhmMappings }

bmcMappings = dict()

ips = [
    "192.168.10.53",
    "192.168.10.57",
    "192.168.10.59",
    "192.168.10.72",
    "192.168.10.65",
    "192.168.10.64",
    "192.168.10.62",
    "192.168.10.68",
    "192.168.10.71",
    "192.168.10.66",
    "192.168.10.61",
    "192.168.10.70",
    "192.168.10.69",
    "192.168.10.60",
    "192.168.10.63",
    "192.168.10.52",
    "192.168.10.96",
    "192.168.10.45",
    "192.168.10.44",
    "192.168.10.46",
    "192.168.10.48",
    "192.168.10.55",
    "192.168.10.56",
    "192.168.10.51",
    "192.168.10.54",
    "192.168.10.40",
    "192.168.10.49",
    "192.168.10.47",
    "192.168.10.43",
    "192.168.10.42",
]

for i, node_name in enumerate(node_names):
    bmcMappings[node_name] = ips[i]

print(bmcMappings)

bmcNodeMappings = { "bmcNodeMappings": bmcMappings }

bmcCredentials = read_yaml("./bmc-credentials.yaml")
bmcConfig = { "bmcUsername": bmcCredentials["username"], "bmcPassword": bmcCredentials["password"] }

local('echo "targetMetricName: fake_energy_target" > ./target-exporter/config-tilt.yaml')
local('echo "{}" >> ./target-exporter/config-tilt.yaml'.format(str(encode_yaml(targets))))
local('echo "{}" >> ./target-exporter/config-tilt.yaml'.format(str(encode_yaml(pyzhmNodeMappings))))
local('echo "{}" >> ./target-exporter/config-tilt.yaml'.format(str(encode_yaml(bmcNodeMappings))))
local('echo "{}" >> ./target-exporter/config-tilt.yaml'.format(str(encode_yaml(bmcConfig))))
local("cp ../ecoqube-wkld-dev.kubeconfig ./target-exporter/")

target_exporter_args = "--config=config-tilt.yaml --kubeconfig=/kubeconfig/ecoqube-dev.kubeconfig --debug=true --cors-disabled=true --promclient-address=http://prom-service.monitoring.svc.cluster.local:9090"

docker_build_with_restart("docker.io/cristianohelio/target-exporter",
  context="target-exporter",
  entrypoint="/go/bin/dlv --continue --listen=0.0.0.0:5050 --api-version=2 --headless=true --only-same-user=false --accept-multiclient --check-go-version=false exec /app/build/target-exporter -- {}".format(target_exporter_args),
  dockerfile="./target-exporter/Dockerfile.dev",
  live_update=[sync("./target-exporter/build/target-exporter", "/app/build/target-exporter"),
  sync("./target-exporter/config-tilt.yaml", "/app/config-tilt.yaml")],
#  only=[
#    './target-exporter/build',
#    './target-exporter/config-tilt.yaml',
#  ]
)
2
# TODO: Eventually find out if helm_resource can be used with live reload in our setup
helm_resource("target-exporter",
  "./target-exporter/charts/target-exporter",
  namespace="target-exporter",
  image_deps=["docker.io/cristianohelio/target-exporter"],
  image_keys=[('image.repository', 'image.tag')],
  flags=["--create-namespace"]
)

k8s_resource(
  "target-exporter", port_forwards=["8080:8080", "5050:5050"] # 5050 is the debugger port
)

helm_resource("job-submission-platform",
  "./job-submission-platform/charts/job-submission-platform",
  namespace="job-submission-platform",
  image_deps=["docker.io/cristianohelio/job-submission-platform"],
  image_keys=[('image.repository', 'image.tag')],
  flags=["--create-namespace"]
)

k8s_resource(
  "job-submission-platform", port_forwards=3000
)

# Add a live_update rule to our docker_build
docker_build_with_restart('docker.io/cristianohelio/job-submission-platform',
    context="job-submission-platform",
    entrypoint='yarn start',
    dockerfile="./job-submission-platform/Dockerfile.dev",
    live_update=[
        sync('job-submission-platform', '/app'),
        run('cd /app && yarn install', trigger=['./package.json', './yarn.lock']),
])

# pyzhm

docker_build('docker.io/cristianohelio/pyzhm',
    context="pyzhm",
    entrypoint="flask run --host 0.0.0.0 --port 5001",
    dockerfile="./pyzhm/Dockerfile",
)

helm_resource("pyzhm",
  "./pyzhm/charts/pyzhm",
  namespace="pyzhm",
  image_deps=["docker.io/cristianohelio/pyzhm"],
  image_keys=[('image.repository', 'image.tag')],
  flags=["--create-namespace"]
)

k8s_resource(
  "pyzhm", port_forwards=["5001:5001"]
)