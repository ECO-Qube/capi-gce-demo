consts = {
    "kinds": ["ClusterResourceSet"],
    "crs_names": ["prometheus", "prometheus-node-exporter", "custom-metrics", "custom-metrics-tls-secret", "tas", "tas-tls-secret", "extender", "calico"]
}

# Init CAPD provider
local('clusterctl init --infrastructure docker')

# Apply cluster resources
k8s_yaml([
    "./templates/crs/calico-configmap.yaml",
    "./templates/crs/custom-metrics-configmap.yaml",
    "./templates/crs/custom-metrics-tls-secret-configmap.yaml",
    "./templates/crs/prometheus-configmap.yaml",
    "./templates/crs/prometheus-node-exporter-configmap.yaml",
    "./templates/crs/scheduler-extender-configmap.yaml",
    "./templates/crs/tas-configmap.yaml",
    "./templates/crs/tas-tls-secret-configmap.yaml",
    "./templates/crs/clusterresourcesets.yaml",
    "./templates/capd/clusterclass-ecoqube-dev.yaml",
    "./templates/capd/cluster-template-ecoqube-dev.yaml"
])

for kind in consts.get("kinds"):
    k8s_kind(kind)

local_resource("wait-for-capi-control-plane-readiness",
  cmd="kubectl wait --for=condition=Ready --timeout=60s pod -l control-plane=controller-manager --all-namespaces",
)

for crs in consts.get("crs_names"):
    k8s_resource("{}".format(crs), labels=["crs"], pod_readiness='ignore', resource_deps=["wait-for-capi-control-plane-readiness"])

#k8s_resource("ecoqube-tas-control-plane:kubeadmcontrolplanetemplate", pod_readiness='ignore')
#cluster_probe = probe(period_secs=2, initial_delay_secs=30, timeout_secs=5*60, exec=exec_action(["kubectl get kubeadmcontrolplane -o=jsonpath='{range .items[*]}{.status.ready}{end}' | grep true"]))
#local_resource(name="kubeconfi g",cmd="clusterctl get kubeconfig ecoqube-dev > ecoqube-dev.kubeconfig", readiness_probe=cluster_probe)